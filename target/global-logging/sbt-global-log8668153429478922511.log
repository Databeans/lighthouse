[0m[[0m[0mdebug[0m] [0m[0m> Exec(testOnly jass.metrics.DeltaClusteringMetricsSpec -- -z "get metrics for a column without statistics", None, None)[0m
[0m[[0m[0mdebug[0m] [0m[0mEvaluating tasks: Test / testOnly[0m
[0m[[0m[0mdebug[0m] [0m[0mRunning task... Cancel: Signal, check cycles: false, forcegc: true[0m
[0m[[0m[0minfo[0m] [0m[0mcompiling 1 Scala source to /Users/abidijasser/databricks/ClusteringInfo/target/scala-2.12/classes ...[0m
[0m[[0m[0minfo[0m] [0m[0mdone compiling[0m
[0m[[0m[0minfo[0m] [0m[0m[32mDeltaClusteringMetricsSpec:[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m- get metrics for a column without statistics *** FAILED ***[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  org.apache.spark.sql.AnalysisException: No such struct field value in id[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.apache.spark.sql.errors.QueryCompilationErrors$.noSuchStructFieldInGivenFieldsError(QueryCompilationErrors.scala:1555)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.apache.spark.sql.catalyst.expressions.ExtractValue$.findField(complexTypeExtractors.scala:82)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.apache.spark.sql.catalyst.expressions.ExtractValue$.apply(complexTypeExtractors.scala:55)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.apache.spark.sql.catalyst.expressions.package$AttributeSeq.$anonfun$resolve$1(package.scala:348)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at scala.collection.IndexedSeqOptimized.foldLeft(IndexedSeqOptimized.scala:60)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at scala.collection.IndexedSeqOptimized.foldLeft$(IndexedSeqOptimized.scala:68)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at scala.collection.mutable.ArrayBuffer.foldLeft(ArrayBuffer.scala:49)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.apache.spark.sql.catalyst.expressions.package$AttributeSeq.resolve(package.scala:347)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveChildren(LogicalPlan.scala:112)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$resolveExpressionByPlanChildren$1(Analyzer.scala:1857)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  ...[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[36mRun completed in 1 minute, 4 seconds.[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[36mTotal number of tests run: 1[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[36mSuites: completed 1, aborted 0[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[36mTests: succeeded 0, failed 1, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m*** 1 TEST FAILED ***[0m[0m
[0m[[0m[31merror[0m] [0m[0mFailed tests:[0m
[0m[[0m[31merror[0m] [0m[0m	jass.metrics.DeltaClusteringMetricsSpec[0m
[0m[[0m[31merror[0m] [0m[0m(Test / [31mtestOnly[0m) sbt.TestsFailedException: Tests unsuccessful[0m
[0m[[0m[31merror[0m] [0m[0mTotal time: 66 s (01:06), completed Oct 26, 2022 10:17:36 PM[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(idea-shell, None, None)[0m
